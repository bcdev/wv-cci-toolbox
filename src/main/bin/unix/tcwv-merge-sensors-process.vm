#!/bin/bash
set -x
set -e
set -m

# Calvalus processing script for the merge of two L3 products from two different sensors. 
# A sensor can also represent a previous merge of sensors.
# So overall we have as valid combinations: 
#     meris-modis_terra
#     meris-cmsaf_hoaps
#     modis_terra-cmsaf_hoaps
#     meris-modis_terra-cmsaf_hoaps
#     olci-cmsaf_hoaps
#     olci-modis_terra
#     olci-modis_terra-cmsaf_hoaps

# e.g.
## from MERIS: /calvalus/projects/wvcci/tcwv/meris/l3-daily/005/2011/07/15-L3-1/l3_tcwv_meris_005deg_2011-07-15_2011-07-15.nc
## copy to local pwd MODIS: /calvalus/projects/wvcci/tcwv/modis_terra/l3-daily/005/2011/07/15-L3-1/l3_tcwv_modis_terra_005deg_2011-07-15_2011-07-15.nc

## from MERIS: /calvalus/projects/wvcci/tcwv/meris/l3-daily/005/2011/07/15-L3-1/l3_tcwv_meris_005deg_2011-07-15_2011-07-15.nc
## copy to local pwd CMSAF-HOAPS: /calvalus/projects/wvcci/tcwv/l3-daily/005/2011/07/15-L3-1/hoaps-g.r03.d01.wvpa.2011-07-15.nc

function copy_file_from_hdfs {
  local filePath=$1
  result=1
  echo "checking HDFS ${filePath}"
  local hadoopLsResult=$(hadoop fs -ls ${filePath})
  if [[ ${hadoopLsResult} ]]; then
    echo "copy to CWD: ${filePath}"
    /opt/hadoop/bin/hadoop fs -copyToLocal $filePath ${pwd}
    result=0
  fi
  return $result
}

sensor1HdfsInputDir="$parameters.get('sensor1InputDir')"
sensor1="$parameters.get('sensor1')"
sensor2="$parameters.get('sensor2')"
res="$parameters.get('res')"
year="$parameters.get('year')"
month="$parameters.get('month')"
day="$parameters.get('day')"
tcwvJarVersion="$parameters.get('tcwvJarVersion')"

#[[

# e.g. 
# MERIS: /calvalus/projects/wvcci/tcwv/meris/l3-daily/005/2011/07/15-L3-1/l3_tcwv_meris_005deg_2011-07-15_2011-07-15.nc
# MODIS: /calvalus/projects/wvcci/tcwv/modis_terra/l3-daily/005/2011/07/15-L3-1/l3_tcwv_modis_terra_005deg_2011-07-15_2011-07-15.nc
# CMSAF_HOAPS: /calvalus/projects/wvcci/tcwv/cmsaf_hoaps/l3-daily/005/2011/07/15-L3-1/hoaps-g.r03.d01.wvpa.2011-07-15.nc

# --> Merge: /calvalus/projects/wvcci/tcwv/meris-modis_terra/l3-daily/005/2011/07/15-L3-1/l3_tcwv_meris-modis_terra_005deg_2011-07-15_2011-07-15.nc
# --> Merge: /calvalus/projects/wvcci/tcwv/meris-cmsaf_hoaps/l3-daily/005/2011/07/15-L3-1/l3_tcwv_meris-cmsaf_hoaps_005deg_2011-07-15_2011-07-15.nc

sensor1_infile=$1
sensor1_infile_name=`basename ${sensor1_infile} .nc`           # l3_tcwv_meris_005deg_2011-07-15_2011-07-15

sensor2HdfsInputDir=${sensor1HdfsInputDir//$sensor1/$sensor2}    # /calvalus/projects/wvcci/tcwv/modis_terra/l3-daily/005/2011/07/15-L3-1
sensor2_infile=$(hadoop fs -ls -C ${sensor2HdfsInputDir}/*.nc)       # /calvalus/projects/wvcci/tcwv/modis_terra/l3-daily/005/2011/07/15-L3-1/l3_tcwv_modis_terra_005deg_2011-07-15_2011-07-15.nc
sensor2_infile_name=$(basename `hadoop fs -ls -C ${sensor2HdfsInputDir}/*.nc`)  # l3_tcwv_modis_terra_005deg_2011-07-15_2011-07-15.nc OR hoaps-g.r03.d01.wvpa.2011-07-15.nc

# copy sensor2 file from HDFS to current dir:
if ! copy_file_from_hdfs ${sensor2_infile}; then
  echo "failed to get sensor2 input file"
  exit 1
fi

sensorsMerge="${sensor1}-${sensor2}"
outfile=${sensor1_infile_name//$sensor1/$sensorsMerge}

echo "`ls -la $(pwd)`"

jars=snap-all.jar:snap-tcwv-${tcwvJarVersion}.jar
class=org.esa.snap.core.gpf.main.GPT

if [[ $sensor2 =~ "hoaps" ]]
then
  ### For wvcci processing in 2.x instance, we need a python3 from a Miniconda which has netCDF4, numpy, scipy, matplotlib
  # (the miniconda package taken from conda-xarray-1.0 instance does the job...): 
  wvcci_py_dir=$(ls -ld miniconda3-wvcci |awk '{print $11}')
  CURRENT_LINK=$(ls -ld /home/yarn/opt/miniconda3-wvcci|awk '{print $11}')
  if [ "$CURRENT_LINK" != "${wvcci_py_dir}" ]; then
    mkdir -p /home/yarn/opt
    ln -s -f -T ${wvcci_py_dir} /home/yarn/opt/miniconda3-wvcci
  fi
  echo "`ls -la ${wvcci_py_dir}/bin/python*`"
  ${wvcci_py_dir}/bin/python3.9 --version

  # in case of HOAPS we need landmask and seaice mask...
  iday=$((10#$day))

  # copy landmask file from HDFS to current dir:
  landmaskFilePath="/calvalus/projects/wvcci/auxdata/landmask/kosh/kosh.r30.lmask.nc"
  echo "KOSH landmask HDFS file path: '${landmaskFilePath}'"
  if ! copy_file_from_hdfs ${landmaskFilePath}; then
    echo "failed to get KOSH landmask file '${landmaskFilePath}'"
    exit 1
  fi
  landmaskFile="kosh.r30.lmask.nc"

  # SNAP-8 cannot deal with the HOAPS nc4 inputs (memory issue?!) - convert to nc3 before gpt call...
  echo "${wvcci_py_dir}/bin/python3.9 $(pwd)/process.py ${sensor1_infile} ${sensor1_infile}3"
  ${wvcci_py_dir}/bin/python3.9 $(pwd)/process.py $(pwd)/${sensor2_infile_name} $(pwd)/${sensor2_infile_name}3

  # copy seaice file from HDFS to current dir:
  seaiceFilePath="/calvalus/projects/wvcci/auxdata/seaice/${year}/hoaps-g.r30.d01.icec.${year}-${month}.nc"
  echo "Seaice HDFS file path: '${seaiceFilePath}'"
  if ! copy_file_from_hdfs ${seaiceFilePath}; then
    echo "failed to get seaice file '${seaiceFilePath}' - will do compliance step without seaice info..."
    echo "Directory listing before processing:"
    echo "`ls -la $(pwd)`"
    # make sure that we have enough memory for SNAP 8 (2048M as for SNAP 7 is not sufficient when dealing with HOAPS products! (20220916)
    # just in case, also make sure to set hdf library paths 
    /usr/lib/jvm/default-java/bin/java -Xmx6G -classpath ${jars} ${class} ESACCI.Tcwv.L3.Merge.Nir.Hoaps.Phase2 \
        -Dncsa.hdf.hdflib.HDFLibrary.hdflib=$(pwd)/libjhdf.so \
        -Dncsa.hdf.hdf5lib.H5.hdf5lib=$(pwd)/libjhdf5.so \
        -Dsnap.home=$(pwd) \
        -Dsnap.userdir=$(pwd) \
        -Djava.io.tmpdir=$(pwd) \
        -SsourceProduct=${sensor1_infile} -ShoapsProduct=$(pwd)/${sensor2_infile_name}3 \
        -Psensor1Name=${sensor1^^} \
        -SlandmaskProduct=$(pwd)/${landmaskFile} \
        -PdayOfMonth=$iday \
        -f NetCDF4-WVCCI -t ./${outfile}.nc
  else
    seaiceFile="hoaps-g.r30.d01.icec.${year}-${month}.nc"
    echo "Directory listing before processing:"
    echo "`ls -la $(pwd)`"
    # make sure that we have enough memory for SNAP 8 (2048M as for SNAP 7 is not sufficient when dealing with HOAPS products! (20220916)
    # just in case, also make sure to set hdf library paths 
    /usr/lib/jvm/default-java/bin/java -Xmx6G -classpath ${jars} ${class} ESACCI.Tcwv.L3.Merge.Nir.Hoaps.Phase2 \
        -Dncsa.hdf.hdflib.HDFLibrary.hdflib=$(pwd)/libjhdf.so \
        -Dncsa.hdf.hdf5lib.H5.hdf5lib=$(pwd)/libjhdf5.so \
        -Dsnap.home=$(pwd) \
        -Dsnap.userdir=$(pwd) \
        -Djava.io.tmpdir=$(pwd) \
        -SsourceProduct=${sensor1_infile} -ShoapsProduct=$(pwd)/${sensor2_infile_name}3 \
        -SlandmaskProduct=$(pwd)/${landmaskFile} \
        -SseaiceProduct=$(pwd)/${seaiceFile} \
        -Psensor1Name=${sensor1^^} \
        -PdayOfMonth=$iday \
        -f NetCDF4-WVCCI -t ./${outfile}.nc
  fi
else
  echo "/usr/lib/jvm/default-java/bin/java -Xmx2048M -classpath ${jars} ${class} ESACCI.Tcwv.L3.Merge.Nir.Nir.Phase2 -Ssensor1Product=${sensor1_infile} -Ssensor2Product=$(pwd)/${sensor2_infile_name} -Psensor1Name=${sensor1^^} -Psensor2Name=${sensor2^^} -f NetCDF4-WVCCI -t ./${outfile}.nc"
  /usr/lib/jvm/default-java/bin/java -Xmx2048M -classpath ${jars} ${class} ESACCI.Tcwv.L3.Merge.Nir.Nir.Phase2 -Ssensor1Product=${sensor1_infile} -Ssensor2Product=$(pwd)/${sensor2_infile_name} -Psensor1Name=${sensor1^^} -Psensor2Name=${sensor2^^} -f NetCDF4-WVCCI -t ./${outfile}.nc
fi

status=$?
echo "Status: $status"

if [ $status = 0 ]
then
    echo "Merge file of $sensor1 and $sensor2 created."
    echo "Status: $status"
fi

echo CALVALUS_OUTPUT_PRODUCT ${outfile}.nc

]]#
